---
title: "Home"
layout: homelay
excerpt: "MR Media Melbourne Center"
sitemap: false
permalink: /
---

### About the Center

The center performs research in the areas where interactive computing meets its human users. As such, our research has applications in almost every domain, from engineering to the arts. Some specific application areas in which our members work include medical imaging, archaeology, and education/training.

Our team consists of internationally-recognized experts from across the broader area of human-computer interaction, with specific expertise in the areas of information visualisation, virtual and augmented reality, interaction design, computer graphics, computer vision and image analysis.  This expertise is evident in our many international and interdisciplinary collaborations. Our members have served as program committee members, steering committee members, and conference chairs at leading conferences including IEEE ISMAR, IEEE VR, ACM VRST, and ACM CHI, and their papers have been published in top venues such as SIGGRAPH, IEEE VR, IEEE ISMAR, IEEE TVCG, ACM CHI, and ACM TOCHI. To learn more about our individual histories and research interests, please click on [Meet the team](/team)

There are five major themes to our current research: augmented, virtual, and mixed reality (AR/VR/MR, collectively referred to as xR), computational design, digital arts and cultural heritage, multimodal human-computer interaction, and visualisation and analytics. For more information regarding each of these research areas, please click on [Research](/research/).

#### **Research Projects**
-	Augmented, Virtual and Mixed Reality

	* Mixed reality applications in education 

		Mixed reality (MR) is an emerging technology which could potentially shape the future of education. The project is to develop mixed reality technologies to facilitate pupils and educators to learn STEAM and explore new pedagogical and learning styles. 

	* Automatic arrangement of objects in virtual environments

		Virtual reality benefits people nowadays regarding learning and amusement, by providing immersive virtual environments with interactive digital media contents, e.g. virtual museums. This project aims to propose an automatic approach that smartly arranges positions and appearances of objects in a virtual environment and provides a satisfactory user experience. Participants will investigate how to integrate stochastic optimisation and deep learning towards a set of design goals and metrics.

	* Investigating cognitive illusions in virtual environments
		It is believed that immersion (the technical qualities of a system) and coherence (the degree to which the experience matches up with user expectations) lead to Place Illusion (the user's feeling that they are in another place) and Plausibility Illusion (the feeling that the events a user is seeing are actually happening). However, there are many questions yet to be answered, including how to measure the feeling of Plausibility Illusion, whether Place Illusion or Plausibility Illusion is more important in various types of applications, and how best to induce these feelings in users. This project investigates these questions and others. 

-	Computational and Interaction Design

	* Optimization of User Interface Design using AI approaches

		UI design is one of important steps for software and computing products. There are numerous researches have been done using different approaches.  The project attempts to explore how to use machine learning approaches to UI design via optimizing information flows and minimize mental workloads.  

	* Urban zoning using graph convolutional networks

		Urban zoning focuses on dividing the land in a city into zones where specific land uses are permitted and serves as the base of land use analysis and urban planning. While a city develops, people must periodically update its zoning map to reflect changes in its urban patterns. Compared with most approaches to land use classification that exploit machine learning on satellite images, this project aims to utilise recent deep learning methods integrated with graph theory for the synthesis of an urban zoning map from a collection of geo-tagged photos about a city from SNS.

	* Urban layout generation using AI-based data-driven optimisation

		An urban layout, which comprises roads and parcels, constitutes the skeleton of a city where numerous people reside and interact with each other. There has been a considerable demand for modelling realistic and functional urban layouts in the areas of city planning, game development, and training. Computer graphics researchers have proposed sound approaches to enable users to focus on high-level design goals instead of laborious fundamental operations supposed to be done by computer systems. These approaches rely on rule-based or example-based systems, which, however, needs expertise for parameters configuration or produces results highly similar to the given ones. This project aims to propose a novel optimisation-based approach that generates urban layouts efficiently from common urban data in integration with the recent deep learning methods.

-	Digital Arts and Cultural Heritage 

	* Generating cultural patterns via AI 

		The project is to explore the applications how computing technologies can help practitioners to archive, preserve and promote cultural heritage.  Couple of studies have been done by using AI algorithm to identify and generate new art patterns.  New forms of art expression also have been explored via understanding context of voices, behaviours and linking to visual elements. 

	* Immersive archaeology

		Archaeologists collect rich and complex spatiotemporal data in the course of their fieldwork. This data, however, frequently lies unused after it is collected because it is difficult to analyse, and the archaeology domain experts frequently lack the time and computational expertise needed to extract maximum value from their data. This project is developing and evaluating immersive tools to enable new archaeological research.


-	Multimodal Human-Computer Interaction

	* Gesture Input for Mobile Interaction Design

		Gesture interaction has arguably become a popular style on mobile devices. Such popularity has increasingly raised many research questions in discussions of gesture interaction such as gesture learning, modelling, recognition and design. This project focuses on gesture design for mobile interaction from three aspects, i.e. input modalities, physical activities and holding postures. This project investigates the effects of these aspects on gesture input for mobile interaction design. The purpose of this project is to design more efficient gesture-driven interfaces for mobile interaction.

	* Gesture Interaction Design for Older Users
		Elderly adults love to use smartphones but sometimes "hate" to do it as well. Using phones aids them to access online info, keep in touch with others et al.; on the other hand, such use is a demanding task when it comes to target selection and function search. Touch gesture interaction (e.g. Google Gesture Search) is a potential solution to this issue as it is eyes-free and button-free. This project investigates two fundamental aspects of gesture interaction for older users: 1) motivation - are older users willing to use gestures? 2) memorization and articulation â€“ what would the performance of older users be in gesture memorization and reproduction? This project aims to design user-friendly gesture interfaces for older people. 

-	Visualisaiton and Analytics

	* Semantic segmentation of biomedical images

		Detection and segmentation of lesions in medical images are routinely performed in radiology centres for patient diagnosis and treatment planning. This process is time-consuming and prone to inter- and intra-observer variations. Computerized methods have been developed to assist precision diagnosis and efficient treatment planning, but there is still much scope of improvement. In this project, we will investigate advanced machine learning models including deep learning algorithms for semantic segmentation of combined healthy and abdominal organs from biomedical images such as liver, heart, and other organs of interest from biomedical images including PET, CT and MRI.

	* Image-centric multimodal data fusion and collaborative learning in biomedical applications

		Multimodal medical imaging and diverse clinical data are the basis for precision biomedicine and personalised healthcare. The utilisation and interpretation of the interaction among various data sources are yet to be investigated. This research aims to look at how computer algorithms can be used to analyse and understand images and relevant health data for enhanced decision support systems. In this project, we will investigate image pattern recognition and machine learning models to improve the modelling of visual features, and to develop new methodologies for data fusion and interpretation with various medical applications. 

	* Immersive visualisation and analytics of biomedical images 

		Multimodality and multidimensional biomedical images are indispensable data resources in current biology and medical science. A prolonged challenge is how to explore the complicated 3D image content effectively and input user-specified information based on the observation and understanding of images directly in the 3D space. This holds great potential and advances for student focus teaching and clinical use in biomedicine and the field of medical imaging. Virtual augmented and mixed reality technologies have attracted great interests in entertainment and gamification. The advances in virtual immersive and augmented reality also provide possibilities to communicate and explore the contents and patterns preserved in biomedical images by different means. This research aims to develop virtual and augmented reality framework and platforms for bridging gaps, particularly for the tasks of visualisation, interaction and analytics of biomedical images with potential applications on novel education and intelligent healthcare.



